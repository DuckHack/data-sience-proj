{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colaborative filtering is a type of recommender systems that makes recommendations (predictions) based only on collected ratings/preferences of many users. To quote Wikipedia:\n",
    "\n",
    "> In the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user ratings can be collected in a rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R_{um}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each row of this matrix corresponds to one user and each column to one item (movie in this example). \n",
    " An entry $R_{um}$ gives the rating of user $u$ for item $m$. This matrix has size $N_u\\times N_m$ where $N_u$ is the number of users and $N_m$ is the numbers of items. This can be a very large number. However ss each of the users has usually rated a (very) small sample of items this matrix is sparse! In case of e.g. Netflix it has only about $1\\%$ of filled entries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the recommender system is to predict the remaining $99\\%$ of entries :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach to this problem is to reduce the  rank of the rating matrix by representing it as a product of two matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{R}_{um} = U_{uk} M_{mk},\\quad \\hat{R}=U\\cdot M^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this formulation each entry of the rating matrix $\\hat R$ is a dot product of a row of users matrix $U$ and a row of movies matrix $M$. We can view each row of movie matrix as a set of _features_ and each row of the users matrix as _preferences_ for each of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features $K$ is a hyperparameter that we have to choose somehow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstructing the rating matrix $\\hat R$ amounts to estimating the matrices $U$ and $M$. This is alltogether  $N_u\\times K + N_u\\times K$ parameters. Depending on $K$ this is usually much smaller number then the number of all entries in $\\hat R$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of $U$ and $M$ is done byminimazing the mean squared error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J=\\frac{1}{2}\\sum_{<u,m>}\\left(R_{um}-\\hat{R}_{um}\\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum is over a set of all non empty entries of matrix $R$ and we denote this by symbol $\\langle u,m\\rangle$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating with respect to an element of the matrix $U$ we obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial }{\\partial {U_{uk}}} J = \\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'}\\right) M_{mk}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above formula idices $u$ and $k$ are fixed and the sum runs over all the movies $m$ rated by the user $u$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equating this derivative to zero gives as an equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{<u,m>} M_{mk}  M_{mk'} U_{uk'} = \\sum_{<u,m>}  R_{um} M_{mk}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which can be rewritten in vector form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\sum_{<u,m>}\\vec{M}_{m}  \\vec{M}_{m}^T\\right) \\vec{U}_{u} = \\sum_{<u,m>}  R_{um} \\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here $\\vec{U}_u$ is the $u$-th row of the matrix $U$ and similarly for $\\vec{M}_m$. The summation is again over all movies $m$ rated by user $u$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way we can derive another set of equation for the rows of the matrix $M$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T\\right) \\vec{M}_{m} = \\sum_{<u,m>}  R_{um} \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimazing the  $J$  requires solving both of those sets of equations simultaneuosly. This cannot be done in general and requires numerical methods. One of the is the iterative merthods of alterneting least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I if we consider $M$ fixed the equiations for the rows of $U$ are ordinary linear equations. Based on this observation the method consists of filling $M$ with same random starting values and the solving for $U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \\vec{U}_{u} = \\left(\\sum_{<u,m>}\\vec{M}_{m}  \\vec{M}_{m}^T\\right)^{-1}\\sum_{<u,m>}  R_{um} \\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then keeping $U$ fixed we solve for $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{M}_{m} =\\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T\\right)  \\sum_{<u,m>}  R_{um} \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the whole process is reapeted until convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the data from the Movielens. Please download and unpack the  ```ml-latest-small.zip``` from their [website](https://grouplens.org/datasets/movielens/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ratings = len(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the number of users and movies in the data set we can use function ```nunique```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 9724\n"
     ]
    }
   ],
   "source": [
    "n_users  = data['userId'].nunique()\n",
    "n_movies = data['movieId'].nunique()\n",
    "print(n_users, n_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the size of the rating matrix, assuming $K=64$ calculate number of parameters we have to fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661376\n"
     ]
    }
   ],
   "source": [
    "n_of_parameters = (n_users + n_movies) * 64\n",
    "print(n_of_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_rating_matrix = csr_matrix((data.rating.values, (data.userId.values, data.movieId.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  4. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       ..., \n",
       "       [ 0. ,  2.5,  2. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  3. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  5. ,  0. , ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_rating_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare number of non empty entries in the rating matrix to number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMPTY ENTRIES: 100836\n",
      "num of parameters: 661376\n"
     ]
    }
   ],
   "source": [
    "print(\"NON EMPTY ENTRIES: \" + str(data.shape[0]))\n",
    "print(\"num of parameters: \" + str(n_of_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare number of paremeters to the size of available data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data: 118295710\n",
      "num of parameters: 661376\n"
     ]
    }
   ],
   "source": [
    "ratings_shape = sparse_rating_matrix.shape\n",
    "print(\"Available data: \" + str(ratings_shape[0] * ratings_shape[1]))\n",
    "print(\"num of parameters: \" + str(n_of_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies that didnt appear in the dataset: 183886\n"
     ]
    }
   ],
   "source": [
    "print('Number of movies that didnt appear in the dataset: ' + str(len(np.where(~sparse_rating_matrix.toarray().any(axis=0))[0]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those calculations show that we still have more parameters to fit then the data. This can (and will) lead to serious overfitting. One way to mitigate that is to use regularisation of the parameters by constraining their size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This amounts to adding another term to the cost function $J$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J=\\frac{1}{2}\\sum_{<u,m>}\\left(R_{um}-\\hat{R}_{um}\\right)^2+\n",
    "\\frac{\\lambda}{2}\\left(\n",
    "||U||^2 +||M||^2\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the norm of the matrix $||U||^2$ denotes the sum of all the squares of the matrix  entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$||U||^2=\\sum_{u,k}U_{ik}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\lambda$ is another hyperparameter to be estimated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking the gradient we obtain new sets of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{U}_{u} = \\left(\\sum_{<u,m>}\\vec{M}_{m}  \n",
    "\\vec{M}_{m}^T+\\lambda I\\right)^{-1}\n",
    "\\sum_{<u,m>} R_{um}\\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{M}_{m} =\\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T+\\lambda I\\right)  \\sum_{<u,m>}  R_{um} \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that we solve in the same iterative way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to implementation we need to split our data into train, test and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac=0.8, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>63</td>\n",
       "      <td>6365</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>62</td>\n",
       "      <td>139385</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66478</th>\n",
       "      <td>428</td>\n",
       "      <td>2004</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45949</th>\n",
       "      <td>305</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38937</th>\n",
       "      <td>268</td>\n",
       "      <td>1210</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating\n",
       "9326       63     6365     2.0\n",
       "9122       62   139385     4.0\n",
       "66478     428     2004     2.0\n",
       "45949     305       34     3.0\n",
       "38937     268     1210     1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test.sample(frac=0.5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69001</th>\n",
       "      <td>448</td>\n",
       "      <td>2269</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74513</th>\n",
       "      <td>474</td>\n",
       "      <td>5944</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35145</th>\n",
       "      <td>235</td>\n",
       "      <td>368</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61023</th>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35971</th>\n",
       "      <td>246</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating\n",
       "69001     448     2269     3.0\n",
       "74513     474     5944     3.5\n",
       "35145     235      368     2.0\n",
       "61023     396        1     5.0\n",
       "35971     246       29     5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(validation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>673</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "0        1        1     4.0\n",
       "6        1      101     5.0\n",
       "12       1      223     3.0\n",
       "24       1      441     4.0\n",
       "39       1      673     3.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_users  = train.userId.nunique()\n",
    "n_train_movies = train.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 9012\n"
     ]
    }
   ],
   "source": [
    "print(n_train_users, n_train_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_users  = test.userId.nunique()\n",
    "n_test_movies = test.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594 3690\n"
     ]
    }
   ],
   "source": [
    "print(n_test_users, n_test_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_validation_users=validation.userId.nunique()\n",
    "n_validation_movies = validation.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602 3648\n"
     ]
    }
   ],
   "source": [
    "print(n_validation_users, n_validation_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing the ALS algorithm we will need to traverse the ratings users by user and for each user iterate over all movies that she has rated. To this end we will define an auxiliary data structur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_user = train.groupby('userId').apply(lambda g: list(zip(g.movieId, g.rating)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a ```pandas.Series``` indexed by the  ```userId``` that contains lists of pairs ```(movieId, rating)``` for each movie rated by this partuclar user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we will need to traverse list of all movies and for each movie traverse list of users that have rated it, so we create another auxiliary structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_movie = train.groupby('movieId').apply(lambda g: list(zip(g.userId, g.rating)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last point to remember is that we cannot(!) use the ```userId``` to index  rows of matrix $U$! This is because the userId are not garantied to be consecutive, especially after spliting the data into three different sets. The correct way of finding the index into the U matrix for given userId is to find it's location in the series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ui = by_user.index.get_loc(uid)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same applies to movies indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mi = by_movie.index.get_loc(mid)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>673</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "0        1        1     4.0\n",
       "6        1      101     5.0\n",
       "12       1      223     3.0\n",
       "24       1      441     4.0\n",
       "39       1      673     3.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Implement the ALS algorithm in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlternatingLeastSquares:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int = 64,\n",
    "        n_iter: int = 100,\n",
    "        λ: float = 4.35,\n",
    "        𝜀: float = 0.05\n",
    "    ):\n",
    "        self.n_features = n_features\n",
    "        self.n_iter = n_iter\n",
    "        self.λ = λ\n",
    "        self.𝜀 = 𝜀\n",
    "        self.features_eye = np.eye(n_features)\n",
    "\n",
    "    def mean_absolute_error(self, y_pred, y_true):\n",
    "        nonZero = y_true != 0\n",
    "        return np.mean(abs(y_pred[nonZero] - y_true[nonZero]))\n",
    "    \n",
    "    def mean_squared_error(self, y_pred, y_true):\n",
    "        nonZero = y_true != 0\n",
    "        return np.mean(np.square(y_pred[nonZero] - y_true[nonZero]))\n",
    "\n",
    "    def normaliseRow(self, x):\n",
    "        return x / sum(x)\n",
    "\n",
    "    def generate_matrix(self, shape):\n",
    "        matrix = abs(np.random.rand(shape[0], shape[1]))\n",
    "        return np.apply_along_axis(self.normaliseRow, 1, matrix)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        X = X\n",
    "        self.U = self.generate_matrix((X.shape[0], self.n_features))\n",
    "        self.M = self.generate_matrix((X.shape[1], self.n_features))\n",
    "        nonZero = X > 0\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            print('Iteration', i + 1, 'of', self.n_iter)\n",
    "            for i in range(X.shape[0]):\n",
    "                idx = nonZero[i,:]\n",
    "                self.U[i] = self._factorise(X[i,idx], self.M[idx,], self.λ, self.features_eye)\n",
    "\n",
    "            for i in range(X.shape[1]):\n",
    "                idx = nonZero[:,i]\n",
    "                self.M[i] = self._factorise(X[idx,i], self.U[idx,], self.λ, self.features_eye)\n",
    "        \n",
    "            mse = self.mean_squared_error(self.predict(), X)\n",
    "            print('Mean Squared Error:', mse)\n",
    "            if mse < self.𝜀:\n",
    "                print('Fitting finished, epsilon =', self.𝜀,'bound reached with MSE =', mse)\n",
    "                return\n",
    "            \n",
    "    def predict(self):\n",
    "        return self._predict(self.U, self.M)\n",
    "    \n",
    "    def _predict(self, U, M):\n",
    "        return U.dot(M.T)\n",
    "            \n",
    "    def _factorise(self, r, X, λ, eye):\n",
    "        a = np.dot(X.T, X) + (λ * eye)\n",
    "        b = np.dot(r.T, X)\n",
    "        return np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Check its predictions on the train, test and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlternatingLeastSquares()\n",
    "\n",
    "mae = model.mean_absolute_error\n",
    "mse = model.mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 9012)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  4. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       ..., \n",
       "       [ 2.5,  2. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 3. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train = train.pivot_table(columns=['movieId'], index=['userId'], values='rating', dropna=False)\n",
    "ratings_train = ratings_train.fillna(0)\n",
    "print(ratings_train.shape)\n",
    "ratings_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 100\n",
      "Mean Squared Error: 2.27849006147\n",
      "Iteration 2 of 100\n",
      "Mean Squared Error: 0.162141386051\n",
      "Iteration 3 of 100\n",
      "Mean Squared Error: 0.120912671079\n",
      "Iteration 4 of 100\n",
      "Mean Squared Error: 0.111299451986\n",
      "Iteration 5 of 100\n",
      "Mean Squared Error: 0.107177717701\n",
      "Iteration 6 of 100\n",
      "Mean Squared Error: 0.104820353602\n",
      "Iteration 7 of 100\n",
      "Mean Squared Error: 0.103291318163\n",
      "Iteration 8 of 100\n",
      "Mean Squared Error: 0.102233049895\n",
      "Iteration 9 of 100\n",
      "Mean Squared Error: 0.101466583001\n",
      "Iteration 10 of 100\n",
      "Mean Squared Error: 0.100887925159\n",
      "Iteration 11 of 100\n",
      "Mean Squared Error: 0.100432705168\n",
      "Iteration 12 of 100\n",
      "Mean Squared Error: 0.10006095817\n",
      "Iteration 13 of 100\n",
      "Mean Squared Error: 0.099748136832\n",
      "Iteration 14 of 100\n",
      "Mean Squared Error: 0.0994790632575\n",
      "Iteration 15 of 100\n",
      "Mean Squared Error: 0.0992440442088\n",
      "Iteration 16 of 100\n",
      "Mean Squared Error: 0.0990365552434\n",
      "Iteration 17 of 100\n",
      "Mean Squared Error: 0.0988519250819\n",
      "Iteration 18 of 100\n",
      "Mean Squared Error: 0.0986866055237\n",
      "Iteration 19 of 100\n",
      "Mean Squared Error: 0.0985377737391\n",
      "Iteration 20 of 100\n",
      "Mean Squared Error: 0.0984031190519\n",
      "Iteration 21 of 100\n",
      "Mean Squared Error: 0.098280725397\n",
      "Iteration 22 of 100\n",
      "Mean Squared Error: 0.0981689975106\n",
      "Iteration 23 of 100\n",
      "Mean Squared Error: 0.0980666047423\n",
      "Iteration 24 of 100\n",
      "Mean Squared Error: 0.0979724329124\n",
      "Iteration 25 of 100\n",
      "Mean Squared Error: 0.0978855427309\n",
      "Iteration 26 of 100\n",
      "Mean Squared Error: 0.0978051355459\n",
      "Iteration 27 of 100\n",
      "Mean Squared Error: 0.0977305266761\n",
      "Iteration 28 of 100\n",
      "Mean Squared Error: 0.0976611254661\n",
      "Iteration 29 of 100\n",
      "Mean Squared Error: 0.097596420482\n",
      "Iteration 30 of 100\n",
      "Mean Squared Error: 0.0975359681291\n",
      "Iteration 31 of 100\n",
      "Mean Squared Error: 0.0974793832799\n",
      "Iteration 32 of 100\n",
      "Mean Squared Error: 0.0974263309859\n",
      "Iteration 33 of 100\n",
      "Mean Squared Error: 0.097376518832\n",
      "Iteration 34 of 100\n",
      "Mean Squared Error: 0.0973296898499\n",
      "Iteration 35 of 100\n",
      "Mean Squared Error: 0.0972856161058\n",
      "Iteration 36 of 100\n",
      "Mean Squared Error: 0.0972440931323\n",
      "Iteration 37 of 100\n",
      "Mean Squared Error: 0.09720493533\n",
      "Iteration 38 of 100\n",
      "Mean Squared Error: 0.0971679723707\n",
      "Iteration 39 of 100\n",
      "Mean Squared Error: 0.0971330465403\n",
      "Iteration 40 of 100\n",
      "Mean Squared Error: 0.0971000108849\n",
      "Iteration 41 of 100\n",
      "Mean Squared Error: 0.0970687279875\n",
      "Iteration 42 of 100\n",
      "Mean Squared Error: 0.0970390691995\n",
      "Iteration 43 of 100\n",
      "Mean Squared Error: 0.09701091417\n",
      "Iteration 44 of 100\n",
      "Mean Squared Error: 0.0969841505494\n",
      "Iteration 45 of 100\n",
      "Mean Squared Error: 0.0969586737785\n",
      "Iteration 46 of 100\n",
      "Mean Squared Error: 0.0969343869062\n",
      "Iteration 47 of 100\n",
      "Mean Squared Error: 0.0969112004039\n",
      "Iteration 48 of 100\n",
      "Mean Squared Error: 0.0968890319594\n",
      "Iteration 49 of 100\n",
      "Mean Squared Error: 0.0968678062451\n",
      "Iteration 50 of 100\n",
      "Mean Squared Error: 0.0968474546599\n",
      "Iteration 51 of 100\n",
      "Mean Squared Error: 0.0968279150454\n",
      "Iteration 52 of 100\n",
      "Mean Squared Error: 0.0968091313781\n",
      "Iteration 53 of 100\n",
      "Mean Squared Error: 0.0967910534403\n",
      "Iteration 54 of 100\n",
      "Mean Squared Error: 0.0967736364703\n",
      "Iteration 55 of 100\n",
      "Mean Squared Error: 0.0967568407928\n",
      "Iteration 56 of 100\n",
      "Mean Squared Error: 0.0967406314334\n",
      "Iteration 57 of 100\n",
      "Mean Squared Error: 0.0967249777182\n",
      "Iteration 58 of 100\n",
      "Mean Squared Error: 0.096709852863\n",
      "Iteration 59 of 100\n",
      "Mean Squared Error: 0.0966952335571\n",
      "Iteration 60 of 100\n",
      "Mean Squared Error: 0.096681099546\n",
      "Iteration 61 of 100\n",
      "Mean Squared Error: 0.0966674332211\n",
      "Iteration 62 of 100\n",
      "Mean Squared Error: 0.0966542192207\n",
      "Iteration 63 of 100\n",
      "Mean Squared Error: 0.0966414440501\n",
      "Iteration 64 of 100\n",
      "Mean Squared Error: 0.0966290957263\n",
      "Iteration 65 of 100\n",
      "Mean Squared Error: 0.0966171634521\n",
      "Iteration 66 of 100\n",
      "Mean Squared Error: 0.0966056373233\n",
      "Iteration 67 of 100\n",
      "Mean Squared Error: 0.0965945080724\n",
      "Iteration 68 of 100\n",
      "Mean Squared Error: 0.0965837668496\n",
      "Iteration 69 of 100\n",
      "Mean Squared Error: 0.0965734050407\n",
      "Iteration 70 of 100\n",
      "Mean Squared Error: 0.0965634141221\n",
      "Iteration 71 of 100\n",
      "Mean Squared Error: 0.0965537855487\n",
      "Iteration 72 of 100\n",
      "Mean Squared Error: 0.0965445106735\n",
      "Iteration 73 of 100\n",
      "Mean Squared Error: 0.0965355806949\n",
      "Iteration 74 of 100\n",
      "Mean Squared Error: 0.0965269866269\n",
      "Iteration 75 of 100\n",
      "Mean Squared Error: 0.0965187192903\n",
      "Iteration 76 of 100\n",
      "Mean Squared Error: 0.0965107693192\n",
      "Iteration 77 of 100\n",
      "Mean Squared Error: 0.0965031271805\n",
      "Iteration 78 of 100\n",
      "Mean Squared Error: 0.0964957832023\n",
      "Iteration 79 of 100\n",
      "Mean Squared Error: 0.0964887276093\n",
      "Iteration 80 of 100\n",
      "Mean Squared Error: 0.0964819505618\n",
      "Iteration 81 of 100\n",
      "Mean Squared Error: 0.0964754421964\n",
      "Iteration 82 of 100\n",
      "Mean Squared Error: 0.0964691926673\n",
      "Iteration 83 of 100\n",
      "Mean Squared Error: 0.0964631921866\n",
      "Iteration 84 of 100\n",
      "Mean Squared Error: 0.096457431062\n",
      "Iteration 85 of 100\n",
      "Mean Squared Error: 0.0964518997317\n",
      "Iteration 86 of 100\n",
      "Mean Squared Error: 0.0964465887965\n",
      "Iteration 87 of 100\n",
      "Mean Squared Error: 0.096441489048\n",
      "Iteration 88 of 100\n",
      "Mean Squared Error: 0.0964365914926\n",
      "Iteration 89 of 100\n",
      "Mean Squared Error: 0.0964318873724\n",
      "Iteration 90 of 100\n",
      "Mean Squared Error: 0.0964273681823\n",
      "Iteration 91 of 100\n",
      "Mean Squared Error: 0.0964230256834\n",
      "Iteration 92 of 100\n",
      "Mean Squared Error: 0.0964188519132\n",
      "Iteration 93 of 100\n",
      "Mean Squared Error: 0.0964148391929\n",
      "Iteration 94 of 100\n",
      "Mean Squared Error: 0.0964109801322\n",
      "Iteration 95 of 100\n",
      "Mean Squared Error: 0.0964072676309\n",
      "Iteration 96 of 100\n",
      "Mean Squared Error: 0.0964036948791\n",
      "Iteration 97 of 100\n",
      "Mean Squared Error: 0.0964002553553\n",
      "Iteration 98 of 100\n",
      "Mean Squared Error: 0.0963969428226\n",
      "Iteration 99 of 100\n",
      "Mean Squared Error: 0.0963937513236\n",
      "Iteration 100 of 100\n",
      "Mean Squared Error: 0.0963906751744\n"
     ]
    }
   ],
   "source": [
    "model.fit(ratings_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 9012)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.99280995,  3.77069897,  4.02054559, ...,  1.92366295,\n",
       "         1.92366295,  2.27025649],\n",
       "       [ 4.04312605,  3.28826066,  3.02903534, ...,  1.26565607,\n",
       "         1.26565607,  1.68630846],\n",
       "       [ 0.56902654,  2.14101485,  1.81015685, ...,  0.73079126,\n",
       "         0.73079126,  0.86395465],\n",
       "       ..., \n",
       "       [ 2.34553928,  2.15994552,  2.97451542, ...,  1.45142217,\n",
       "         1.45142217,  2.12435351],\n",
       "       [ 3.13879281,  3.04282366,  2.70646179, ...,  0.89499208,\n",
       "         0.89499208,  1.22966197],\n",
       "       [ 5.64210748,  5.24451968,  2.84431026, ...,  2.61994648,\n",
       "         2.61994648,  2.60840393]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict()\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem  is that the validation and test sets may contain users and/or movies that are not present in the training set. In this case the prediction is impossible. We can check this at the level of caclulating the prediction score or clean up those sets beforehand.  We will clean up the sets using an inner join on two dataframes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we prepare two dataframes that contain only index which constists of unique users(movies) Id from the training sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_user_idx = pd.DataFrame(index = by_user.index)\n",
    "by_movie_idx = pd.DataFrame(index = by_movie.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col_values = ratings_train.columns.values\n",
    "train_idx_values = ratings_train.index.values\n",
    "predictions_df = pd.DataFrame(predictions, index=train_idx_values, columns=train_col_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this frames in join. Inner join keeps only the rows with keys apearing in both dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.join(by_user_idx, on='userId', how='inner')\n",
    "test = test.join(by_movie_idx, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test = test.pivot_table(columns=['movieId'], index=['userId'], values='rating', dropna=False)\n",
    "ratings_test.fillna(0, inplace=True)\n",
    "\n",
    "test_col_values = ratings_test.columns.values\n",
    "test_idx_values = ratings_test.index.values\n",
    "\n",
    "test_ratings = ratings_train[np.intersect1d(train_col_values, test_col_values)].loc[np.intersect1d(train_idx_values, test_idx_values)]\n",
    "test_preds = predictions_df[np.intersect1d(train_col_values, test_col_values)].loc[np.intersect1d(train_idx_values, test_idx_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = validation.join(by_user_idx, on='userId', how='inner')\n",
    "validation = validation.join(by_movie_idx, on='movieId', how='inner')\n",
    "\n",
    "validation_test = validation.pivot_table(columns=['movieId'], index=['userId'], values='rating', dropna=False)\n",
    "validation_test.fillna(0, inplace=True)\n",
    "\n",
    "validation_col_values = validation_test.columns.values\n",
    "validation_idx_values = validation_test.index.values\n",
    "\n",
    "validation_ratings = ratings_train[np.intersect1d(train_col_values, validation_col_values)].loc[np.intersect1d(train_idx_values, validation_idx_values)]\n",
    "validation_preds = predictions_df[np.intersect1d(train_col_values, validation_col_values)].loc[np.intersect1d(train_idx_values, validation_idx_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Model parameters:\n",
      "    K - 64\n",
      "    λ - 4.35\n",
      "    max_i - 100\n",
      "-----------------------\n",
      "[Training set] MSE: 0.0963906751744\n",
      "[Training set] MAE: 0.214857926503\n",
      "[Test set] MSE: 0.0832501166619\n",
      "[Test set] MAE: 0.1993677571\n",
      "[Validation set] MSE: 0.0832395970817\n",
      "[Validation set] MAE: 0.199707643283\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------')\n",
    "print('Model parameters:')\n",
    "print('    K -', model.n_features)\n",
    "print('    λ -', model.λ)\n",
    "print('    max_i -', model.n_iter)\n",
    "print('-----------------------')\n",
    "print('[Training set] MSE:', mse(predictions_df.values, ratings_train.values))\n",
    "print('[Training set] MAE:', mae(predictions_df.values, ratings_train.values))\n",
    "print('[Test set] MSE:', mse(test_preds.values, test_ratings.values))\n",
    "print('[Test set] MAE:', mae(test_preds.values, test_ratings.values))\n",
    "print('[Validation set] MSE:', mse(validation_preds.values, validation_ratings.values))\n",
    "print('[Validation set] MAE:', mae(validation_preds.values, validation_ratings.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Does the result depend on number of features (K)? How?\n",
    "\n",
    "Large K definitely hits the performance (time complexity) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Does the result depend on $\\lambda$? How?\n",
    "\n",
    "With lower $\\lambda$ model tends to overfit the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend our model by adding additional \"biases\" and mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{R}_{um} = U_{uk} M_{mk} + b_u +c_m +\\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mu$ is just overall mean (on training set):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mu = \\frac{1}{\\sum_{<u,m> } 1}\\sum_{<u,m>}R_{um}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate gradient with respwect to biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial }{\\partial {b_{u}}} J = \\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'}- b_u -c_m -\\mu\\right) \\cdot 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'}- b_u -c_m -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{<u,m>}  b_u =\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'} -c_m -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and obtain te final equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{U}_{u} = \\left(\\sum_{<u,m>}\\vec{M}_{m}  \n",
    "\\vec{M}_{m}^T+\\lambda I\\right)^{-1}\n",
    "\\sum_{<u,m>} \\left( R_{um} - b_u -c_m -\\mu\\right)\\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{M}_{m} =\\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T+\\lambda I\\right)  \\sum_{<u,m>} \\left( R_{um} - b_u -c_m -\\mu\\right) \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ b_u =\\frac{1}{\\lambda+\\sum_{<u,m>} 1}\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'} -c_m -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ c_m =\\frac{1}{\\lambda+\\sum_{<u,m>} 1}\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'} -b_u -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve this equations in the same way, we start from random values and  solve each equation by keeping all other varaibles fix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Implement this version of the ALS algorithm and compare it's performance with the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSB:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int = 64,\n",
    "        n_iter: int = 3,\n",
    "        λ: float = 4.44,\n",
    "        𝜀: float = 0.1\n",
    "    ):\n",
    "        self.n_features = n_features\n",
    "        self.n_iter = n_iter\n",
    "        self.λ = λ\n",
    "        self.𝜀 = 𝜀\n",
    "        self.features_eye = np.eye(n_features)\n",
    "\n",
    "    def mean_absolute_error(self, y_pred, y_true):\n",
    "        nonZero = y_true != 0\n",
    "        return np.mean(abs(y_pred[nonZero] - y_true[nonZero]))\n",
    "    \n",
    "    def mean_squared_error(self, y_pred, y_true):\n",
    "        nonZero = y_true != 0\n",
    "        return np.mean(np.square(y_pred[nonZero] - y_true[nonZero]))\n",
    "\n",
    "    def normaliseRow(self, x):\n",
    "        return x / sum(x)\n",
    "\n",
    "    def generate_matrix(self, shape):\n",
    "        matrix = abs(np.random.rand(shape[0], shape[1]))\n",
    "        return np.apply_along_axis(self.normaliseRow, 1, matrix)\n",
    "    \n",
    "    def fit(self, X, mu):\n",
    "        self.U = self.generate_matrix((X.shape[0], self.n_features))\n",
    "        self.M = self.generate_matrix((X.shape[1], self.n_features))\n",
    "        self.Ub = np.zeros(X.shape[0])\n",
    "        self.Mb = np.zeros(X.shape[1])\n",
    "        nonZero = X > 0\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            print('Iteration', i + 1, 'of', self.n_iter)\n",
    "            #Update biases\n",
    "            #Ub\n",
    "            for i, u in enumerate(train.userId.unique()):\n",
    "                accum = 0\n",
    "                for j, m in enumerate(train.movieId.unique()):\n",
    "                    accum += X[i,j] - np.dot( self.U[i], self.M[j] ) - self.Mb[j] - mu.values[0]\n",
    "                self.Ub[i] = accum/(train.movieId.nunique() + self.λ)\n",
    "            #Mb\n",
    "            for j, m in enumerate(train.movieId.unique()):\n",
    "                accum = 0\n",
    "                for i, u in enumerate(train.userId.unique()):\n",
    "                    accum += X[i,j] - np.dot( self.U[i], self.M[j] ) - self.Ub[i] - mu.values[0]\n",
    "                self.Mb[j] = accum/(train.userId.nunique() + self.λ)\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                idx = nonZero[i,:]\n",
    "                self.U[i] = self._factorise(X[i,idx], self.M[idx,], self.λ, self.features_eye,\n",
    "                                            self.Ub[i], self.Mb[idx,], mu.values[0])\n",
    "\n",
    "            for i in range(X.shape[1]):\n",
    "                idx = nonZero[:,i]\n",
    "                self.M[i] = self._factorise(X[idx,i], self.U[idx,], self.λ, self.features_eye,\n",
    "                                            self.Ub[idx,], self.Mb[i], mu.values[0])\n",
    "        \n",
    "            mse = self.mean_squared_error(self.predict(mu.values[0]), X)\n",
    "            print('Mean Squared Error:', mse)\n",
    "            if mse < self.𝜀:\n",
    "                print('Fitting finished, epsilon =', self.𝜀,'bound reached with MSE =', mse)\n",
    "                return\n",
    "           \n",
    "    def predict(self, mu):\n",
    "        return self._predict(self.U, self.M, self.Ub, self.Mb, mu)\n",
    "    \n",
    "    def _predict(self, U, M, Ub, Mb, mu):       \n",
    "        UM = U.dot(M.T)\n",
    "        UM_Mb = np.ndarray(shape=(UM.shape[0],UM.shape[1]))\n",
    "        for i in range(UM.shape[0]):\n",
    "            UM_Mb[i] = UM[i] + Mb\n",
    "            \n",
    "        UM_Mb_Ub = np.ndarray(shape=(UM.shape[0],UM.shape[1]))\n",
    "        for j in range(UM.shape[1]):\n",
    "            UM_Mb_Ub[:,j] = UM_Mb[:,j] + Ub\n",
    "\n",
    "        R = UM_Mb_Ub + mu\n",
    "        return R  \n",
    "\n",
    "    def _factorise(self, r, X, λ, eye, Ub, Mb, mu):\n",
    "        a = np.dot(X.T, X) + (λ * eye)\n",
    "        b = np.dot((r-Ub.T-Mb-mu), X)\n",
    "        return np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALSB()\n",
    "#mae = model.mean_absolute_error\n",
    "#mse = model.mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean( train[['rating']] )\n",
    "\n",
    "ratings_train = train.pivot_table(columns=['movieId'], index=['userId'], values='rating', dropna=False)\n",
    "ratings_train = ratings_train.fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 3\n",
      "Mean Squared Error: 2.08680558085\n",
      "Iteration 2 of 3\n",
      "Mean Squared Error: 0.150512036991\n",
      "Iteration 3 of 3\n",
      "Mean Squared Error: 0.0998288949081\n",
      "Fitting finished, epsilon = 0.1 bound reached with MSE = 0.0998288949081\n"
     ]
    }
   ],
   "source": [
    "model.fit(ratings_train, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 33649  91542 182639  26649 103233   1984 104875   8369  27762 127096] <- max indexes\n",
      "[  6598   6638   2181 179817  88672    238 117849  26750 106330  93022] <- min indexes\n",
      "\n",
      "max biases -> [ 1.69921501  1.69921532  1.69921658  1.82573353  1.69921806  1.699221\n",
      "  1.69922384  1.74978205  1.69921924  1.69921882]\n",
      "min biases -> [ -8.53912904 -11.71808385  -9.13205028 -10.38720695  -8.53920612\n",
      "  -8.51163295  -8.68452876 -10.31264722  -9.43245625  -8.31746031]\n"
     ]
    }
   ],
   "source": [
    "max_ind = np.argpartition(model.Mb, -10)[-10:]\n",
    "min_ind = np.argpartition(model.Mb, 10)[:10]\n",
    "max_movie_biases = train.movieId.unique()[max_ind]\n",
    "min_movie_biases = train.movieId.unique()[min_ind]\n",
    "print( max_movie_biases, \"<- max indexes\" )\n",
    "print( min_movie_biases, \"<- min indexes\" )\n",
    "print()\n",
    "print(\"max biases ->\", model.Mb[max_ind])\n",
    "print(\"min biases ->\", model.Mb[min_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Using the ```movies.csv``` set associate the movies with biases. Print top ten movies with highest bias, and top ten with lowest (negative). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------WITH MAX BIASES-------------------------------\n",
      "      movieId               title                genres\n",
      "5906    33649  Saving Face (2004)  Comedy|Drama|Romance\n",
      "      movieId                                      title  \\\n",
      "7770    91542  Sherlock Holmes: A Game of Shadows (2011)   \n",
      "\n",
      "                                              genres  \n",
      "7770  Action|Adventure|Comedy|Crime|Mystery|Thriller  \n",
      "      movieId                                  title            genres\n",
      "9667   182639  The Second Renaissance Part II (2003)  Animation|Sci-Fi\n",
      "      movieId                 title                   genres\n",
      "5545    26649  Lonesome Dove (1989)  Adventure|Drama|Western\n",
      "      movieId                                            title  \\\n",
      "8195   103233  LEGO Batman: The Movie - DC Heroes Unite (2013)   \n",
      "\n",
      "                          genres  \n",
      "8195  Action|Adventure|Animation  \n",
      "      movieId                                      title  genres\n",
      "1461     1984  Halloween III: Season of the Witch (1982)  Horror\n",
      "      movieId                               title  \\\n",
      "8254   104875  History of Future Folk, The (2012)   \n",
      "\n",
      "                               genres  \n",
      "8254  Adventure|Comedy|Musical|Sci-Fi  \n",
      "      movieId               title                                genres\n",
      "5167     8369  Mindhunters (2004)  Action|Crime|Horror|Mystery|Thriller\n",
      "      movieId                         title  genres\n",
      "5691    27762  Comic Book: The Movie (2004)  Comedy\n",
      "      movieId                   title           genres\n",
      "8728   127096  Project Almanac (2015)  Sci-Fi|Thriller\n",
      "--------------------------------WITH MIN BIASES-------------------------------\n",
      "      movieId                    title       genres\n",
      "4470     6598  Step Into Liquid (2002)  Documentary\n",
      "      movieId               title          genres\n",
      "4489     6638  Valley Girl (1983)  Comedy|Romance\n",
      "      movieId          title                          genres\n",
      "1635     2181  Marnie (1964)  Drama|Mystery|Romance|Thriller\n",
      "      movieId                title     genres\n",
      "9644   179817  Darkest Hour (2017)  Drama|War\n",
      "      movieId                     title  genres\n",
      "7659    88672  Our Idiot Brother (2011)  Comedy\n",
      "     movieId                                              title  \\\n",
      "204      238  Far From Home: The Adventures of Yellow Dog (1...   \n",
      "\n",
      "                 genres  \n",
      "204  Adventure|Children  \n",
      "      movieId                  title  genres\n",
      "8598   117849  La Belle Verte (1996)  Comedy\n",
      "      movieId                      title                   genres\n",
      "5568    26750  Quigley Down Under (1990)  Adventure|Drama|Western\n",
      "      movieId              title                genres\n",
      "8292   106330  Last Vegas (2013)  Comedy|Drama|Romance\n",
      "      movieId               title        genres\n",
      "7828    93022  Miss Nobody (2010)  Comedy|Crime\n"
     ]
    }
   ],
   "source": [
    "print( \"------------------------------WITH MAX BIASES-------------------------------\" )\n",
    "for max in max_movie_biases:\n",
    "    print( movies.loc[movies['movieId'] == max] )\n",
    "print(\"--------------------------------WITH MIN BIASES-------------------------------\")\n",
    "for min in min_movie_biases:\n",
    "    print( movies.loc[movies['movieId'] == min] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
