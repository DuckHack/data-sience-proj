{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colaborative filtering is a type of recommender systems that makes recommendations (predictions) based only on collected ratings/preferences of many users. To quote Wikipedia:\n",
    "\n",
    "> In the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user ratings can be collected in a rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R_{um}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each row of this matrix corresponds to one user and each column to one item (movie in this example). \n",
    " An entry $R_{um}$ gives the rating of user $u$ for item $m$. This matrix has size $N_u\\times N_m$ where $N_u$ is the number of users and $N_m$ is the numbers of items. This can be a very large number. However ss each of the users has usually rated a (very) small sample of items this matrix is sparse! In case of e.g. Netflix it has only about $1\\%$ of filled entries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the recommender system is to predict the remaining $99\\%$ of entries :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach to this problem is to reduce the  rank of the rating matrix by representing it as a product of two matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{R}_{um} = U_{uk} M_{mk},\\quad \\hat{R}=U\\cdot M^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this formulation each entry of the rating matrix $\\hat R$ is a dot product of a row of users matrix $U$ and a row of movies matrix $M$. We can view each row of movie matrix as a set of _features_ and each row of the users matrix as _preferences_ for each of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features $K$ is a hyperparameter that we have to choose somehow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstructing the rating matrix $\\hat R$ amounts to estimating the matrices $U$ and $M$. This is alltogether  $N_u\\times K + N_u\\times K$ parameters. Depending on $K$ this is usually much smaller number then the number of all entries in $\\hat R$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of $U$ and $M$ is done byminimazing the mean squared error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J=\\frac{1}{2}\\sum_{<u,m>}\\left(R_{um}-\\hat{R}_{um}\\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum is over a set of all non empty entries of matrix $R$ and we denote this by symbol $\\langle u,m\\rangle$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating with respect to an element of the matrix $U$ we obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial }{\\partial {U_{uk}}} J = \\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'}\\right) M_{mk}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above formula idices $u$ and $k$ are fixed and the sum runs over all the movies $m$ rated by the user $u$. We also use the summation conventions according to which a duplicated index ($k'$ in this case) implies a summation over this index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equating this derivative to zero gives as an equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{<u,m>} M_{mk}  M_{mk'} U_{uk'} = \\sum_{<u,m>}  R_{um} M_{mk}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which can be rewritten in vector form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\sum_{<u,m>}\\vec{M}_{m}  \\vec{M}_{m}^T\\right) \\vec{U}_{u} = \\sum_{<u,m>}  R_{um} \\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here $\\vec{U}_u$ is the $u$-th row of the matrix $U$ and similarly for $\\vec{M}_m$. The summation is again over all movies $m$ rated by user $u$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way we can derive another set of equation for the rows of the matrix $M$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T\\right) \\vec{M}_{m} = \\sum_{<u,m>}  R_{um} \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimazing the  $J$  requires solving both of those sets of equations simultaneuosly. This cannot be done in general and requires numerical methods. One of the is the iterative merthods of alterneting least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I if we consider $M$ fixed the equiations for the rows of $U$ are ordinary linear equations. Based on this observation the method consists of filling $M$ with same random starting values and the solving for $U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \\vec{U}_{u} = \\left(\\sum_{<u,m>}\\vec{M}_{m}  \\vec{M}_{m}^T\\right)^{-1}\\sum_{<u,m>}  R_{um} \\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then keeping $U$ fixed we solve for $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{M}_{m} =\\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T\\right)  \\sum_{<u,m>}  R_{um} \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the whole process is reapeted until convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the data from the Movielens. Please download and unpack the  ```ml-latest-small.zip``` from their [website](https://grouplens.org/datasets/movielens/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ratings = len(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the number of users and movies in the data set we can use function ```nunique```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 9724\n"
     ]
    }
   ],
   "source": [
    "n_users  = data['userId'].nunique()\n",
    "n_movies = data['movieId'].nunique()\n",
    "print(n_users, n_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the size of the rating matrix, assuming $K=64$ calculate number of parameters we have to fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661376\n"
     ]
    }
   ],
   "source": [
    "n_of_parameters = (n_users + n_movies) * 64\n",
    "print(n_of_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_rating_matrix = sp.sparse.csr_matrix((data.rating.values, (data.userId.values, data.movieId.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 4. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [0. , 2.5, 2. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 3. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 5. , 0. , ..., 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_rating_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare number of non empty entries in the rating matrix to number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMPTY ENTRIES: 100836\n",
      "num of parameters: 661376\n"
     ]
    }
   ],
   "source": [
    "print(\"NON EMPTY ENTRIES: \" + str(data.shape[0]))\n",
    "print(\"num of parameters: \" + str(n_of_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare number of paremeters to the size of available data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data: 118295710\n",
      "num of parameters: 661376\n"
     ]
    }
   ],
   "source": [
    "ratings_shape = sparse_rating_matrix.shape\n",
    "print(\"Available data: \" + str(ratings_shape[0] * ratings_shape[1]))\n",
    "print(\"num of parameters: \" + str(n_of_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies that didnt appear in the dataset: 183886\n"
     ]
    }
   ],
   "source": [
    "print('Number of movies that didnt appear in the dataset: ' + str(len(np.where(~sparse_rating_matrix.toarray().any(axis=0))[0]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those calculations show that we still have more parameters to fit then the data. This can (and will) lead to serious overfitting. One way to mitigate that is to use regularisation of the parameters by constraining their size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This amounts to adding another term to the cost function $J$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J=\\frac{1}{2}\\sum_{<u,m>}\\left(R_{um}-\\hat{R}_{um}\\right)^2+\n",
    "\\frac{\\lambda}{2}\\left(\n",
    "||U||^2 +||M||^2\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the norm of the matrix $||U||^2$ denotes the sum of all the squares of the matrix  entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$||U||^2=\\sum_{u,k}U_{ik}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\lambda$ is another hyperparameter to be estimated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking the gradient we obtain new sets of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{U}_{u} = \\left(\\sum_{<u,m>}\\vec{M}_{m}  \n",
    "\\vec{M}_{m}^T+\\lambda I\\right)^{-1}\n",
    "\\sum_{<u,m>} R_{um}\\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{M}_{m} =\\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T+\\lambda I\\right)  \\sum_{<u,m>}  R_{um} \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that we solve in the same iterative way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to implementation we need to split our data into train, test and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac=0.9, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66938</th>\n",
       "      <td>432</td>\n",
       "      <td>5630</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73408</th>\n",
       "      <td>474</td>\n",
       "      <td>1198</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80038</th>\n",
       "      <td>502</td>\n",
       "      <td>45</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23969</th>\n",
       "      <td>166</td>\n",
       "      <td>3897</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54930</th>\n",
       "      <td>365</td>\n",
       "      <td>2716</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating\n",
       "66938     432     5630     4.5\n",
       "73408     474     1198     4.0\n",
       "80038     502       45     3.5\n",
       "23969     166     3897     3.5\n",
       "54930     365     2716     3.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test.sample(frac=0.5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89974</th>\n",
       "      <td>584</td>\n",
       "      <td>508</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>501</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73364</th>\n",
       "      <td>474</td>\n",
       "      <td>1041</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92687</th>\n",
       "      <td>599</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69845</th>\n",
       "      <td>448</td>\n",
       "      <td>73321</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating\n",
       "89974     584      508     5.0\n",
       "80003     501       17     3.0\n",
       "73364     474     1041     4.5\n",
       "92687     599      160     2.5\n",
       "69845     448    73321     3.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =test.drop(validation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>736</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "3        1       47     5.0\n",
       "14       1      235     4.0\n",
       "17       1      316     3.0\n",
       "41       1      736     3.0\n",
       "65       1     1097     5.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_users  = train.userId.nunique()\n",
    "n_train_movies = train.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 9379\n"
     ]
    }
   ],
   "source": [
    "print(n_train_users, n_train_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_users  = test.userId.nunique()\n",
    "n_test_movies = test.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 2497\n"
     ]
    }
   ],
   "source": [
    "print(n_test_users, n_test_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_validation_users=validation.userId.nunique()\n",
    "n_validation_movies = validation.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551 2452\n"
     ]
    }
   ],
   "source": [
    "print(n_validation_users, n_validation_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing the ALS algorithm we will need to traverse the ratings users by user and for each user iterate over all movies that she has rated. To this end we will define an auxiliary data structur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_user = train.groupby('userId').apply(lambda g: list(zip(g.movieId, g.rating)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a ```pandas.Series``` indexed by the  ```userId``` that contains lists of pairs ```(movieId, rating)``` for each movie rated by this partuclar user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we will need to traverse list of all movies and for each movie traverse list of users that have rated it, so we create another auxiliary structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_movie = train.groupby('movieId').apply(lambda g: list(zip(g.userId, g.rating)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last point to remember is that we cannot(!) use the ```userId``` to index  rows of matrix $U$! This is because the userId are not garantied to be consecutive, especially after spliting the data into three different sets. The correct way of finding the index into the U matrix for given userId is to find it's location in the series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ui = by_user.index.get_loc(uid)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same applies to movies indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mi = by_movie.index.get_loc(mid)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>736</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "3        1       47     5.0\n",
       "14       1      235     4.0\n",
       "17       1      316     3.0\n",
       "41       1      736     3.0\n",
       "65       1     1097     5.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Implement the ALS algorithm in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://danielnee.com/2016/09/collaborative-filtering-using-alternating-least-squares/\n",
    "class AlternatingLeastSquares:\n",
    "    def __init__(\n",
    "            self,\n",
    "            ratings,\n",
    "            n_features: int = 64,\n",
    "            n_iter: int = 10,\n",
    "            α: float = 40,\n",
    "            λ: float = 1.0,\n",
    "            𝜀: float = 0.1\n",
    "    ):\n",
    "        self.ratings = ratings\n",
    "        self.n_features = n_features\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "        self.α = α\n",
    "        self.λ = λ\n",
    "        self.𝜀 = 𝜀\n",
    "    \n",
    "        self.U = np.random.randn(ratings.shape[0], n_features)\n",
    "        self.U_eye = np.eye(self.U.shape[0])\n",
    "        self.M = np.random.randn(n_features, ratings.shape[1])\n",
    "        self.M_eye = np.eye(self.M.shape[1])\n",
    "        self.features_eye = np.eye(n_features)\n",
    "        self.setup_prefereces(ratings)\n",
    "        self.setup_confidence(ratings)\n",
    "        \n",
    "    def setup_prefereces(self, ratings):\n",
    "        preferences = ratings.copy()\n",
    "        preferences[preferences != 0] = 1\n",
    "        self.preferences = preferences\n",
    "        \n",
    "    def setup_confidence(self, ratings):\n",
    "        confidence = ratings.copy()\n",
    "        confidence[confidence != 0] *= self.α\n",
    "        self.confidence = confidence\n",
    "        \n",
    "    def mean_squared_error(y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def fit(self, X):\n",
    "        i = 0\n",
    "        while i < self.n_iter and self.𝜀 < 1:\n",
    "            uTu = self.U.T.dot(self.U)\n",
    "            mTm = self.M.T.dot(self.M)\n",
    "            \n",
    "            self.U = _optimise(mTm, self.confidence, self.λ, self.eye, self.preferences)\n",
    "            self.M = _optimise(uTu, self.confidence, self.λ, self.eye, self.preferences)\n",
    "            i += 1\n",
    "            \n",
    "    def _optimise(self, X, C, λ, eye, p):\n",
    "        return np.linalg.inv(Y.T.dot(C.dot(X) + (λ * eye))).dot(X.T).dot(C).dot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlternatingLeastSquares(sparse_rating_matrix)\n",
    "\n",
    "model.fit(sparse_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def implicit_als(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    " \n",
    "    \"\"\" \n",
    "    Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "    compute the user (x_u) and item (y_i) vectors using the following formulas:\n",
    " \n",
    "    x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "    y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    " \n",
    "    Args:\n",
    "        sparse_data (csr_matrix): Our sparse user-by-item matrix\n",
    " \n",
    "        alpha_val (int): The rate in which we'll increase our confidence\n",
    "        in a preference with more interactions.\n",
    " \n",
    "        iterations (int): How many times we alternate between fixing and \n",
    "        updating our user and item vectors\n",
    " \n",
    "        lambda_val (float): Regularization value\n",
    " \n",
    "        features (int): How many latent features we want to compute.\n",
    "    \n",
    "    Returns:     \n",
    "        X (csr_matrix): user vectors of size users-by-features\n",
    "        \n",
    "        Y (csr_matrix): item vectors of size items-by-features\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the foncidence for each value in our data\n",
    "    confidence = sparse_data * alpha_val\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "    \n",
    "    #Precompute I and lambda * I\n",
    "    X_I = sparse.eye(user_size)\n",
    "    Y_I = sparse.eye(item_size)\n",
    "    \n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n",
    "    \n",
    "    # Start main loop. For each iteration we first compute X and then Y\n",
    "    for i in range(iterations):\n",
    "        print('iteration %d of %d' % (i+1, iterations))\n",
    "        \n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "\n",
    "            # Get the user row.\n",
    "            u_row = confidence[u,:].toarray() \n",
    "\n",
    "            # Calculate the binary preference p(u)\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "\n",
    "            # Calculate Cu and Cu - I\n",
    "            CuI = sparse.diags(u_row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            yT_CuI_y = Y.T.dot(CuI).dot(Y)\n",
    "            yT_Cu_pu = Y.T.dot(Cu).dot(p_u.T)\n",
    "            X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "\n",
    "    \n",
    "        for i in range(item_size):\n",
    "\n",
    "            # Get the item column and transpose it.\n",
    "            i_row = confidence[:,i].T.toarray()\n",
    "\n",
    "            # Calculate the binary preference p(i)\n",
    "            p_i = i_row.copy()\n",
    "            p_i[p_i != 0] = 1.0\n",
    "\n",
    "            # Calculate Ci and Ci - I\n",
    "            CiI = sparse.diags(i_row, [0])\n",
    "            Ci = CiI + X_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            xT_CiI_x = X.T.dot(CiI).dot(X)\n",
    "            xT_Ci_pi = X.T.dot(Ci).dot(p_i.T)\n",
    "            Y[i] = spsolve(xTx + xT_CiI_x + lI, xT_Ci_pi)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Check its predictions on the train, test and validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem  is that the validation and test sets may contain users and/or movies that are not present in the training set. In this case the prediction is impossible. We can check this at the level of caclulating the prediction score or clean up those sets beforehand.  We will clean up the sets using an inner join on two dataframes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we prepare two dataframes that contain only index which constists of unique users(movies) Id from the training sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_user_idx = pd.DataFrame(index = by_user.index)\n",
    "by_movie_idx = pd.DataFrame(index=by_movie.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this frames in join. Inner join keeps only the rows with keys apearing in both dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.join(by_user_idx, on='userId', how='inner')\n",
    "test=test.join(by_movie_idx, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=validation.join(by_user_idx, on='userId', how='inner')\n",
    "validation=validation.join(by_movie_idx, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Does the result depend on number of features (K)? How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Does the result depend on $\\lambda$? How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend our model by adding additional \"biases\" and mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{R}_{um} = U_{uk} M_{mk} + b_u +c_m +\\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mu$ is just overall mean (on training set):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mu = \\frac{1}{\\sum_{<u,m> } 1}\\sum_{<u,m>}R_{um}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate gradient with respwect to biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial }{\\partial {b_{u}}} J = \\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'}- b_u -c_m -\\mu\\right) \\cdot 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'}- b_u -c_m -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{<u,m>}  b_u =\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'} -c_m -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and obtain te final equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{U}_{u} = \\left(\\sum_{<u,m>}\\vec{M}_{m}  \n",
    "\\vec{M}_{m}^T+\\lambda I\\right)^{-1}\n",
    "\\sum_{<u,m>} \\left( R_{um} - b_u -c_m -\\mu\\right)\\vec{M}_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\vec{M}_{m} =\\left(\\sum_{<u,m>}\\vec{U}_{u}  \\vec{U}_{u}^T+\\lambda I\\right)  \\sum_{<u,m>} \\left( R_{um} - b_u -c_m -\\mu\\right) \\vec{U}_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ b_u =\\frac{1}{\\lambda+\\sum_{<u,m>} 1}\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'} -c_m -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ c_m =\\frac{1}{\\lambda+\\sum_{<u,m>} 1}\\sum_{<u,m>} \\left(R_{um} - U_{uk'} M_{mk'} -b_u -\\mu\\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve this equations in the same way, we start from random values and  solve each equation by keeping all other varaibles fix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Implement this version of the ALS algorithm and compare it's performance with the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Using the ```movies.csv``` set associate the movies with biases. Print top ten movies with highest bias, and top ten with lowest (negative). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
